<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>SkyScapes</title>
	<!-- <link rel="stylesheet" href="http://cdn.static.runoob.com/libs/bootstrap/3.3.7/css/bootstrap.min.css">     -->
	<link rel="stylesheet" href="bootstrap-3.3.7-dist/css/bootstrap.min.css">
	<link rel="stylesheet" type="text/css" href="css/mystyle.css">
	<script src="http://cdn.static.runoob.com/libs/jquery/2.1.1/jquery.min.js"></script>
</head>

<body>
	<div class="container">

		<div class="content">
			<h1 style="text-align:center; margin-top:60px; font-weight: bold">
				Skyscapes -- Fine-Grained Semantic Understanding of Aerial Scenes
			</h1>
			<p style="text-align:center; margin-bottom:15px; margin-top:20px; font-size: 18px">
				<a href="https://www.dlr.de/eoc/en/desktopdefault.aspx/tabid-5242/8788_read-33610/sortby-lastname/">Seyed Majid Azimi</a>,
				<a>Corentin Henry</a>,
				<a>Lars Sommer</a>,
				<a>Arne Schumann</a>,
				<a>Eleonora Vig</a>.
			</p>
		</div>

		<div class="row">
			<div class="span6 offset2">
				<ul class="nav nav-tabs">
					<li class="active"> <a href="../WUDA-RSImg/index.html">Home</a></li>
					<li> <a href="dataset.html">Dataset</a></li>
					<li>
						<a href="external.html">External</a>
					</li>
					<li><a href="tasks.html">Tasks</a></li>
					<li><a href="evaluation.html">Evaluation</a></li>
					<li><a href="results.html">Results</a></li>
					<br />
				</ul>
			</div>
		</div>

		<div class="row">
			<div class="span12">
				<h3 style="text-align:left; margin-bottom:10px; margin-top:20px; ">
					News
				</h3>
				<ul>
					<!-- <li style="font-size:16px">
					<strong>2018-05-29</strong>
					We are mataining the server from 2018-05-29 to 2018-06-02. Try not to submit data during maintenance. If you submit data during maintenance, we cannot guarantee that data will not be lost.
					<strong class="news">New</strong>
			</li> -->
					<!-- <li style="font-size:16px">
						<strong>2019-11-10</strong> <a href="http://138.201.132.223:82/">Evaluation server</a> is online. <strong class="news">New</strong>
					</li>
					<li style="font-size:16px">
						<strong>2019-11-01</strong> "A dataset for Fine-Grained Semantic Understanding of Aerial Scenes" (<a
							href="https://captain-whu.github.io/iSAID/">iSAID</a>) has been released. <strong
							class="news">New</strong>
					</li>
					<li style="font-size:16px">
						<strong>2019-06-14</strong> The <a
							href="https://github.com/dingjiansw101/RoITransformer_DOTA">code</a> of “Learning RoI
						Transformer for Detecting Oriented Objects in Aerial Images” has released. <strong
							class="news">New</strong>
					</li>
					<li style="font-size:16px">
						<strong>2019-03-05</strong> <a
							href="https://captain-whu.github.io/DOAI2019/dataset.html">DOTA-v1.5</a> has released.
						<strong class="news">New</strong>
					</li>
					<li style="font-size:16px">
						<strong>2019-02-25</strong> Our work <a href="https://arxiv.org/abs/1812.00155"> “Learning RoI
							Transformer for Detecting Oriented Objects in Aerial Images”</a> has been accepted by
						CVPR’2019. <strong class="news">New</strong>
					</li>
					<li style="font-size:16px">
						<strong>2018-08-19</strong> We updated the leaderboard.
					</li>
					<li style="font-size:16px">
						<strong>2018-06-27</strong> You can make comments on the <a
							href="http://119.23.15.48:8001/">evaluation server page</a> now.
					</li>
					<li style="font-size:16px">
						<strong>2018-06-24</strong> All the trained models mentioned in paper were released. You can
						find it in the Dataset page.
					</li>
					<li style="font-size:16px">
						<strong>2018-04-30</strong> The code of <a
							href="https://github.com/jessemelpolio/Faster_RCNN_for_DOTA">Faster-RCNN OBB</a> is
						released.
					</li>


					<li style="font-size:16px">
						<strong>2018-03-20</strong> Fix little bug on gsd of annotation.
					</li>
					<li style="font-size:16px">
						<strong>2018-03-16</strong> The registration for <a
							href="https://captain-whu.github.io/ODAI/">ODAI</a> is open now.
					</li>
					<li style="font-size:16px">
						<strong>2018-03-14</strong> We updated the results on the baseline algorithms in results page.
					</li>
					<li style="font-size:16px">
						<strong>2018-03-8</strong> DOTA <a href="https://github.com/CAPTAIN-WHU/DOTA_devkit">development
							kit</a> ia available now. It's helpful to play on DOTA!
					</li>
					<li style="font-size:16px">
						<strong>2018-02-19</strong> The article of <a href="https://arxiv.org/abs/1711.10398">DOTA</a>
						has been accepted by <a href="http://cvpr2018.thecvf.com/">CVPR'2018</a>.
					</li>
					<li style="font-size:16px">
						<strong>2018-02-08</strong> <a href="https://captain-whu.github.io/ODAI/">ODAI</a>：a contest of
						object detection in aerial images on <a href="http://www.icpr2018.org/">ICPR'2018</a>, is now
						open!
					</li>
					<li style="font-size:16px">
						<strong>2018-01-27</strong> A problem of annotations is fixed and a new-version annotation has
						been released.
					</li> -->
					<li style="font-size:16px">
						<strong>2019-11-06</strong> SkyScapes-v1.0 released with all images and annotations for training and vallidation set.
					</li>
				</ul>
				<h3>
					Description
				</h3>
				<p style="text-align:justify; font-size: 17px">
					Understanding  the  complex  urban  infrastructure  with centimeter-level accuracy is essential for many applications
from autonomous driving to mapping, infrastructure monitoring,  and  urban  management.    Aerial  images  provide
valuable  information  over  a  large  area  instantaneously; nevertheless,  no  current  dataset  captures  the  complexity
of  aerial  scenes  at  the  level  of  granularity  required  by real-world  applications.
To  address  this,  we  introduce SkyScapes,  an  aerial  image  dataset  with  highly-accurate,
fine-grained annotations for pixel-level semantic labeling.
SkyScapes provides annotations for 31 semantic categories
ranging  from  large  structures,  such  as  buildings,  roads
and vegetation, to fine details, such as 12 (sub-)categories
of  lane  markings.    We  have  defined  two  main  tasks  on
this dataset:  dense semantic segmentation and multi-class
lane-marking  prediction.

For the <strong style="color:blue"> SkyScapes-v1.0</strong>, as described in the <a
	href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Azimi_SkyScapes__Fine-Grained_Semantic_Understanding_of_Aerial_Scenes_ICCV_2019_paper.pdf">paper</a>, it contains <strong
	style="color:blue">2806</strong> aerial images from different sensors and platforms.
Each image with the size of <strong style="color:blue"> 5616 &times 3744 </strong> pixels
and contains objects exhibiting a wide variety of scales, orientations, and shapes. These SkyScapes
images are then annotated by experts in aerial image interpretation.

These 31 semantic classes introduce different challenges. Therefore, we have defined the following benchmarks:
1) SkyScapes-Dense with 20 classes as the lane-markings were merged into a single class, 2) SkyScapes-Lane with 13 classes
comprising 12 lane-marking classes and a non-lane-marking one, 3) SkyScapes-Dense-Category with 11 merged classes comprising
nature (low-vegetation, tree), driving-area (paved, non-paved), parking-area (paved, non-paved), human-area (bikeway, sidewalk,
danger area), shared human and vehicle area (entrance/exit), road-feature (lane-marking), residential area (building),
dynamic-vehicle (car, van, truck, large-truck, bus), static-vehicle (trailer), man-made surface (impervious surface),
and others objects (clutter), 4) SkyScapes-Dense-Edge-Binar, for binary edge segmentation and 5) SkyScapesDense-Edge-Multi
 for multi-class edge segmentation.
The fully annotated
SkyScapes images contains <strong style="color:blue">70,346</strong> instances, each of which is labeled by a polygon.

</p>
<p style="text-align:justify; font-size: 17px">
We split the dataset into training, validation, and test sets with 50%, 12.5%, and 37.5% portions respectively.
We chose this particular split due to the class imbalance and to avoid splitting larger images. The training and
validation sets will be publicly available. Test images will be released as an online benchmark with undisclosed ground-truth.
</p>

				<p style="text-align:justify; font-size: 17px">
The images were acquired by the German Aerospace Center (DLR) with airborne acquisition flights over several cities in Germany
and several European countries. The data collection was carried out with a helicopter or aircraft, Germany using a low-cost camera
array system consisting of three DSLR cameras mounted on a flexible platform for recording the data. Only the nadir-looking images
 were selected. In total, 16 non-overlapping RGB images of size 5616x3744 pixels were chosen. The flight altitude of about 1000m above
 ground led to a GSD of approximately 13cm/pixel. The images represent urban and partly rural areas with highways, first/second order roads,
 and complex traffic situations, such as crossings and congestion.
				</p>


				<p style="text-align:justify; font-size: 17px">
					For more details, refer to the <a href="https://arxiv.org/abs/1711.10398"> <strong
							style="color:blue">arXiv preprint</strong></a> of DOTA.
				</p>
				<h3>
					Examples of Annotated Images
				</h3>
				<img src="DLR-SkyScapes_2.jpg" class="img-responsive center-block" />
				<img src="DLR-SkyScapes_1.jpg" class="img-responsive center-block" />
				<img src="DLR-SkyScapes_org_size_image.jpg" class="img-responsive center-block" />

				<div class="section bibtex">
					<h3>
						Citation
					</h3>
					<p> If you make use of the DOTA dataset, please cite our following paper: </p>
					<pre>
@InProceedings{Xia_2018_CVPR,
author = {Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei},
title = {DOTA: A Large-Scale Dataset for Object Detection in Aerial Images},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
	</pre>
					<pre>
@InProceedings{Ding_2019_CVPR,
author = {Jian Ding, Nan Xue, Yang Long, Gui-Song Xia, Qikai Lu},
title = {Learning RoI Transformer for Detecting Oriented Objects in Aerial Images},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}
	</pre>
				</div>
				<h3>
					Communicate
				</h3>
				<p>
					For any problem you have in using DOTA or ODAI, you can join the WeChat group and communicate.
				</p>
				<img src="images/wechat7.png" height="200" width="200" />
				<p>
					Because the number of WeChat groups exceeds 100, invitations are needed, so the discussion group is
					moved to the <a href="https://jq.qq.com/?_wv=1027&k=5cs05Gq">QQ group</a>.
				</p>
				<p>
					<strong style="color:red">You can also ask questions and comment on the comment area of the <a
							href="http://117.78.28.204:8001/">evaluation server page</a> now.</strong>
				</p>
				<h3>
					Contact
				</h3>
				<p>
					If you have any the problem or feedback in using DOTA, please contact
					<ul>
						<li>Gui-Song Xia at <strong>guisong.xia@whu.edu.cn</strong>, </li>
						<li>Xiang Bai at <strong>xbai@hust.edu.cn</strong>, </li>
						<li>Jian Ding at <strong>jian.ding@whu.edu.cn</strong>,</li>
						<li>Zhen Zhu at <strong>zzhu@hust.edu.cn</strong>.</li>
						<li>Zhipeng Lin at <strong>linzhipeng@whu.edu.cn</strong>,</li>
					</ul>
				</p>
				<br>
			</div>
		</div>
	</div>
	<br>
	<!--<div align="center">
		<a href="http://www.amazingcounters.com"><img border="0"
				src="http://cc.amazingcounters.com/counter.php?i=3220030&c=9660403" alt="AmazingCounters.com"></a>
	</div> -->
			<p align="center">
			<a href="https://clustrmaps.com/site/1ayvp"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=Vs7kEm-F-yc_I1yR89KMrjHwPuM3LWsU-RKxnqEQh3s&cl=ffffff" /></a>
		</p>

	<br>

	</div>

</body>

</html>
